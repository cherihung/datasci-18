### Unit 1: Research Design & Data Analysis	(L1 - L4, L5)

# L1: 02-28-2017

- `Scikit-learn` machine learning
- DS unifies terminology, research and approaches of 3 disciplines: applied stat, AI, econometrics

- covariates: variables that you don't manipulate as part of the experiment but do affect the outcome (e.g. age)
- predicator: variable to manipulate in an experiment to affect the outcome (e.g. calories consumed a day)

## DS workflow

1. ID the problem: objectives, goals, questions 
2. Acquire the data: ideal data vs available data; limitations
3. Parse the data: exploratory analysis, verify quality; are there outliers or trends? what types are the variables?
4. Mining the data: determine sampiling, address missing values
5. Refine the data
6. Build Model
7: Share result

---

# L2: 03-02-2017

## what is a good question?

- SMART (specific, measurable, attainable, reproducible, time-bound)
- identify the high level, philosophical question, then create a SMART question(s) that answers the high level Q

## type of data

- *cross-sectional data:* represents a snapshot or slice of the informaiton. e.g. facebook news feed; stock-ticker information right now. 
	-it's normally more representative but can be difficult to establish casuality with limited time

- *longitudinal data (time-series):* info repeated gathered over time on a subject. e.g. health data, polling data, tweets over time, trends over time 
	- each data point of a longitudinal data set is/can be a cross-sectional data
	- clear sequence, multiple outcomes can be meaasured but prone to have missing or incomplete data

## linear algebra

- matrix is a collection of vectors. vector example: [0, 1, 2]. 4x3 matrix is a matrix with 4 rows and 3 colums.
- matrix is usually written with capital letter. e.g. A = [...]

## Class Activities:

1. 1b uses the smart frame work and wants to know how much weather plays a role in flight delays in the winter season. 1a isn't a smart frame work question. its high-level phil question is to if carry-on causes people to board slower and causing delays.

2. delay data is cross-sectional and longitudinal data. yes, you can create cross-sectional from longitudinal by taking a slice of data or data points from that collection.

3. titanic.csv from [kaggle](https://www.kaggle.com/c/titanic/data)
it's a cross-sectional data set that can be used to measure rate of survivial based on a variety of personal attributes. whether a passenger has other family members on board affects chance of survival, which has more affects age or social-status?

4. matrix of birds on each continents
birds = bluejay, seagull, penguin, ostrich for rows
continents = n. america, africa, antartica for cols

bluejay = [100, 200, 300]
seagull = [300, 100, 200]
penguin = [0, 0, 500]
ostrich = [0, 100, 0]

# L3: 03-07-2017

# Summary of Statistics

- IQR is a way to define low and high outliers. Bounds are sometimes referred to as *fences*.
- Variance: how data vary from the mean. Standard deviation = square root of the variance
- distribution: frequency of value and the probablity of each value existing in a data model
- normal distribution/Gaussian: when mean = media, evenly spaced distribution. aka bell curve. 2 key params - mean and stand deviation. changing mean shifts the x-axis, changing SD shifts the y-axis or height
- left-skewed = white spaces on the left, hump on the right. vice versa for right-skewed.
- [kurtosis](https://brownmath.com/stat/shape.htm#Kurtosis) referes to peak. very pointy curve = positive kurtosis. it tells about the stand. deviation of the data. a pointy K shows most of the data points are close to the mean or one number
- scaling = transform a non-normal distribution to a normal one

## other distribution types
- unitform: less likely but more common with generators
- exponential/power law: high starting peak, long tail. e.g. googel search ranking
- binomial: many yes/no experiments
- poisson: rate of events. x of events within a time/space

## variable types

- continuous, categorical, ordinal
- you can use ordinal to desripbe categorical but it isn't a good idea because numbers infer relationship to each other, which causes problem if using machine learning. could use dummy variable (i.e. 0=true, 1=false) instead

Quesiton:
1. 
16, 18, 18, 24, 17, 21, 24, 29
49, 68, 75, 75, 84, 87, 92, 98
2. why are mean and median sometimes different? data aren't symmetrical.
3. in a distribution chart, ends are *tail*, center of distribution is the *head*
4. continuous prob distribution's modes are the peaks of the chart

5. DC metro delay data's distribution: non-normal, negatively skewed (right-skewed), close to negative kurtois (aka more flattened out and not centered around a single number)

6. dummy variables for metro lines: blue, red, green, orange, siler and yellow. silver as reference.
silver line is the reference variable. Each Line is a column, each row will use 0 and 1 to indicate if it belongs to that column. Silver refrence variable means to drop it out of the dataframe. This is good for mutually exclusive dataset when you can only have one column per row being true.

# L4: 03-09-2017

##correlation

- *correlation matrix* is useful to identify *collinearity* or lack of independence between variables. interpreting the heatmap matrix is to make sure other than the diagonal there aren't any 1s or -1s.	
- perfect collinearity can break certian models (r = 0 or r = 1). collinearity is almost always present.
- collinearity no effect on p-values and predictiveness of most models
- collinearity + confounding variables = causation is hard
- to disprove confounding variables, apply the variables to data and determine collinearity. if it has low collinearity to rest of data, then it has no effect or causation

## hypothesis testing, p-values

- tp prove a *statistically significant* difference
- *null hypothesis* = default, no differences
- low p-value or < .05 you can say there is a significant difference. value range 0.001 to 0.099. 0.001 to 0.003 = highly significant. 
- type 1 error: reject null when it's true. type 2 error: accept null when it's false

### choosing a hypothesis test

## 1-Sample vs 2-Sample tests. Sample is a portion of a population. e.g. height of boys vs girls would be a 2-Sample tests.

### 1-sample test
- KS Test
-- compare 2 distributions. compare data to normal distribution or to ther data. dataset need not be normal.
-- test is looking for a goodness of the fit between the compared data. most commonly used to test if a data's distribution fits a normal distribution pattern

- 1-sample mean test for normal distribution data only 
-- Z-test need to know the standard deviation of the population (which is rare to have)
-- T-test take a small group to predict how likely the data will fall into the mean

- the test attaches meaning - mean/median: will the same represent the mean of overall population? does it cross the threshhold to make it different?  

### 2-sample test
- independence test: does one sample's value affect the other?
- questions to ask: 1 - are they both normally distributed (ks-test)?, 2: are they independent? 3 
- Depdendent T-test: must be normally distributed

- can compare means/medias of two samples
- can compare variances (or standard deviation) of two samples. 

### Applications
- hypothesis tests to make inference about unavailable data
- use same to generalize: polling data, A/B testing, generalize time-bound data

### Confidence Interval
- to see how sensetive or robust our point estimates (singel values data) are to variation in the data, we randomly sample our data 100 times. then take the same measure each time. 
- for normal data can just use panda python, for non-normal: find middle 95% of the sample using quantile

Question - 
conduct a national survey of 1000 respondants wiht how many hours they watch to find out how much TV americans watch?

1. what is the population? can we obtain the standard deviation? All americans. 
2. KS Test to see if data is of normal distribution.
3. what number? between 0.001 to 0.099 p-value. if < 0.05, means there are significant differences between our data and the normal data and we can't use our data to test the hypothesis. we have to collect new data.
4. 30e3 = 30000; 8e-2 = 0.08
5. Comparing distributions = KS Test
6. Run a KS-test first to see if the data is normally distributed. Then if you know the standardard deviation of the population, the run K-test else use T-Test

what test to use?

1. Mean 2-sample T-test to test mean/median 
2. Mann-Whitney test to look at the mead/media of a normal and a non-normal data
3. Barlette test to look at the variance for normally distributed data for dependency
4. Depdent T-test
